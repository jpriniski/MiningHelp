{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine Reddit Data with PRAW and save in a long format excel dataframe\n",
    "Hunter Priniski (priniski@ucla.edu)\n",
    "\n",
    "__Note.__ Before running this script, I advise you glance at the PRAW documentation: https://praw.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Follow Oauth set up here https://redditclient.readthedocs.io/en/latest/oauth/\n",
    "reddit = praw.Reddit(client_id='',\n",
    "                     client_secret='',\n",
    "                     password='',\n",
    "                     user_agent=''\n",
    "                     username='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replies to a given comment will be represented as a list of reply IDs. Useful for constructing discussion trees\n",
    "#You can remove this function if you perfer the _replies data structure returned by the Reddit API \n",
    "def get_replies(comment):\n",
    "    replies = comment['_replies']._comments\n",
    "\n",
    "    replies_list = []\n",
    "\n",
    "    if len(replies) > 0:\n",
    "\n",
    "        for reply in replies:\n",
    "            replies_list.append(reply.id)\n",
    "\n",
    "        return replies_list\n",
    "\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the complete set of comments from a discussion (Note. Here, replies are stored as a list of IDs)\n",
    "def get_comments(submission):\n",
    "    \n",
    "    comments = []\n",
    "    com = submission.comments.replace_more(limit=submission.num_comments)\n",
    "    com_tree = submission.comments[:]\n",
    "\n",
    "    while com_tree:\n",
    "        comment = com_tree.pop(0)                    \n",
    "        com_tree.extend(comment.replies)\n",
    "        comments.append(comment)\n",
    "\n",
    "    data_dicts = []\n",
    "    \n",
    "    for comment in comments:\n",
    "        comment_dict = vars(comment)\n",
    "        comment_body = comment_dict['body']\n",
    "        data_dict = {field:comment_dict[field] for field in comment_dict.keys()}\n",
    "        data_dict['_replies'] = get_replies(comment_dict)\n",
    "        \n",
    "        try: \n",
    "            data_dict['author'] = vars(data_dict['author'])['name']\n",
    "        \n",
    "        except TypeError: \n",
    "            continue\n",
    "            \n",
    "        data_dicts.append(data_dict)\n",
    "\n",
    "    return data_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we store the discussion data as a JSON object in a directory labeled `reddit_data`. I stringify some objects to allow for this. All JSON objects will be saved in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the name of the subreddit as a string\n",
    "subreddit_name = ''\n",
    "subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "# you can change which type of posts you would like to collect here\n",
    "for submission in subreddit.top(limit = 1000):\n",
    "    \n",
    "    submission_dict = vars(submission)\n",
    "    author = submission_dict['author']\n",
    "    post = {field:submission_dict[field] for field in submission_dict.keys()}\n",
    "    post['_comments'] = get_comments(submission)\n",
    "    if post['author']: \n",
    "        post['author'] = vars(post['author'])['name']\n",
    "    else: \n",
    "        post['author'] = 'NA'\n",
    "    post['_reddit'] = '_reddit'\n",
    "    post['subreddit'] = subreddit_name\n",
    "    \n",
    "    for comment in post['_comments']:\n",
    "        comment['_submission'] = comment['_submission'].id\n",
    "        comment['_reddit'] = '_reddit'\n",
    "        comment['subreddit'] = subreddit_name\n",
    "        \n",
    "    with open('reddit_data/'+ post['name'] +'.json', 'w') as outfile:\n",
    "        print(\"Wrote %s as JSON File\" % post['name'])\n",
    "        json.dump(post, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all JSON objects saved in memory into a single list\n",
    "posts = [] \n",
    "directory = os.fsencode('reddit_data/')     \n",
    "\n",
    "for file in os.listdir(directory): \n",
    "    filename = os.fsdecode(file)    \n",
    "    if filename.endswith(\".json\"):  \n",
    "        \n",
    "        with open('reddit_data/' + filename, 'r') as json_file:\n",
    "            post = json.load(json_file)\n",
    "            posts.append(post)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a list of lists using the JSON objects saved in our `reddit_data` folder. Each sublist will be a row in the final dataframe, and the metalist will be the complete dataframe. In the final dataframe, each row represents a single comment in the discussion. I like to create trim dataframes without all of the metadata. However, if there is data that you would like to include, you can index the discussion like a Python dictionary. Hence, `posts[0].keys()` will return the dicsusison level metadata and `posts[0]['_comment'].keys()` will return the comment level metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "#create a trim dataframe of reddit posts\n",
    "for post in posts:\n",
    "    subreddit = post['subreddit']\n",
    "    title = post['title']\n",
    "    selftext = post['selftext']\n",
    "    selftext_html = post['selftext_html']\n",
    "    name = post['name']\n",
    "    author = post['author']\n",
    "    score = post['score']\n",
    "    \n",
    "    \n",
    "    for comment in post['_comments']:\n",
    "        \n",
    "        comment_replies = comment['_replies']\n",
    "        comment_body = comment['body']\n",
    "        comment_html = comment['body_html']    \n",
    "        comment_name = comment['name']\n",
    "        comment_author = comment['author']\n",
    "        comment_score = comment['ups']\n",
    "    \n",
    "        replies = comment['_replies']\n",
    "        \n",
    "        row = [subreddit, title, selftext, selftext_html, name, author, score,\n",
    "              comment_replies, comment_body, comment_html, comment_name, comment_author, comment_score]\n",
    "        \n",
    "        df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label the objects in the row list. This will become our dataframe header, so use clear labels\n",
    "cols = ['subreddit', 'title', 'selftext', 'selftext_html', 'name', 'author', 'score',\n",
    "              'comment_replies', 'comment_body', 'comment_html', 'comment_name', 'comment_author', 'comment_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the list of lists to a pandas dataframe\n",
    "DF = pd.DataFrame(df, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the dataframe to an excel file\n",
    "DF.to_excel('reddit_data.xlsx', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
